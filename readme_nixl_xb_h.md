# æœ¯è¯­/æŠ€æœ¯è¦ç‚¹

- é€šä¿¡ç›¸å…³: æ¨ç†é‡Œé¢æœ‰å‡ ä¸ªåœ°æ–¹ä¼šç”¨åˆ°é€šä¿¡ 1. TP/DP/EPçš„å¹¶è¡Œè®¡ç®— 2. KV cacheçš„ä¼ è¾“ï¼Œ è¿™ä¸ªprç®—æ˜¯ä¸ªåˆ‡å…¥ç‚¹ï¼Œ ç†è§£kv cache æ€ä¹ˆé€šè¿‡nixl connector æ¥ä¼ è¾“ï¼Œ é›†æˆæµ‹è¯•é‡Œé¢åº”è¯¥æœ‰åœ¨æ¡†æ¶å±‚çš„è°ƒç”¨
- get_xfer_descs
- prep_xfer_dlist





# nixlå›è°ƒå‡½æ•°

```bash
/Users/xb/project/ai/llm/vllm/vllm/distributed/kv_transfer/kv_connector/v1/nixl_connector.py
  809,17:         descs = self.nixl_wrapper.get_reg_descs(caches_data,
  812,9:         self.nixl_wrapper.register_memory(descs)
  833,17:         descs = self.nixl_wrapper.get_xfer_descs(blocks_data,
  836,37:         self.src_xfer_side_handle = self.nixl_wrapper.prep_xfer_dlist(
  842,28:             agent_metadata=self.nixl_wrapper.get_agent_metadata(),
  911,29:         remote_agent_name = self.nixl_wrapper.add_remote_agent(
  982,17:         descs = self.nixl_wrapper.get_xfer_descs(blocks_data,
  985,26:             engine_id] = self.nixl_wrapper.prep_xfer_dlist(
  1063,23:         for notifs in self.nixl_wrapper.get_new_notifs().values():
  1095,30:                 xfer_state = self.nixl_wrapper.check_xfer_state(handle)
  1097,21:                     self.nixl_wrapper.release_xfer_handle(handle)
  1177,13:             self.nixl_wrapper.send_notif(agent_name, notif_msg=notif_id)
  1231,18:         handle = self.nixl_wrapper.make_prepped_xfer(
  1241,9:         self.nixl_wrapper.transfer(handle)
```





# æµ‹è¯•kv cache block

ä½ è¿™æ®µä»£ç æ˜¯ä¸€ä¸ª **å•å…ƒæµ‹è¯•**ï¼Œä¸»è¦éªŒè¯åœ¨ **prompt token æ•°é‡å°äºä¸€ä¸ª KV cache block å¤§å°æ—¶**ï¼Œè°ƒåº¦é€»è¾‘æ˜¯å¦æ­£ç¡®ã€‚ä¸‹é¢é€è¡Œè§£æï¼š

---

### 1. æµ‹è¯•ç›®çš„è¯´æ˜

```python
"""
Test that we can handle case where prompt is < block.

In this case, the P worker will send empty remote_block_ids.
The D worker should not schedule an async read in this case,
since there is nothing to pull.
"""
```

* **åœºæ™¯**ï¼šè¾“å…¥ prompt çš„ token æ•°é‡ä¸è¶³ä¸€ä¸ª blockã€‚
* **æœŸæœ›è¡Œä¸º**ï¼š

  * P workerï¼ˆPrefill workerï¼‰ä¸ä¼šäº§ç”Ÿ remote\_block\_idsï¼ˆå› ä¸ºæ ¹æœ¬æ²¡æœ‰å®Œæ•´çš„ block å¯ä»¥ offloadï¼‰ã€‚
  * D workerï¼ˆDecode workerï¼‰ä¹Ÿä¸åº”è¯¥å‘èµ·å¼‚æ­¥è¯»è¯·æ±‚ï¼ˆasync readï¼‰ï¼Œå› ä¸ºæ²¡æœ‰æ•°æ®éœ€è¦ä»è¿œç«¯æ‹‰å–ã€‚

---

### 2. åˆå§‹åŒ–é…ç½®

```python
vllm_config = create_vllm_config()
scheduler = create_scheduler(vllm_config)
```

* è·å– vLLM çš„é…ç½®å¯¹è±¡ `vllm_config`ã€‚
* ç”¨è¯¥é…ç½®åˆå§‹åŒ–ä¸€ä¸ª `scheduler`ï¼ˆè°ƒåº¦å™¨ï¼‰ã€‚

---

### 3. å®šä¹‰æµ‹è¯•åœºæ™¯ï¼šå°äºä¸€ä¸ª block çš„ token

```python
BLOCK_SIZE = vllm_config.cache_config.block_size
NUM_TOKENS = int(BLOCK_SIZE * 0.5)
```

* `BLOCK_SIZE`ï¼šKV Cache ä¸­ä¸€ä¸ª block èƒ½å®¹çº³å¤šå°‘ tokenã€‚
* `NUM_TOKENS`ï¼šå–ä¸€åŠ block å¤§å°ï¼ˆå³å°äºä¸€ä¸ªå®Œæ•´ blockï¼‰ã€‚

---

### 4. æ„é€ è¯·æ±‚

```python
request = create_request(request_id=1,
                         num_tokens=NUM_TOKENS,
                         do_remote_prefill=True,
                         num_remote_blocks=0)
```

* `request_id=1`ï¼šè¯·æ±‚ç¼–å·ã€‚
* `num_tokens=NUM_TOKENS`ï¼šè¯·æ±‚çš„ prompt token æ•°é‡ä¸è¶³ä¸€ä¸ª blockã€‚
* `do_remote_prefill=True`ï¼šè¯´æ˜è¯¥è¯·æ±‚æ”¯æŒè¿œç«¯ prefillã€‚
* `num_remote_blocks=0`ï¼šå› ä¸ºä¸è¶³ä¸€å—ï¼Œæ‰€ä»¥ remote block æ•°é‡ä¸º 0ã€‚

---

### 5. æäº¤è¯·æ±‚å¹¶æ‰§è¡Œè°ƒåº¦

```python
scheduler.add_request(request)
scheduler_output = scheduler.schedule()
```

* æŠŠè¯·æ±‚äº¤ç»™è°ƒåº¦å™¨ã€‚
* è°ƒç”¨è°ƒåº¦å‡½æ•°ï¼Œè·å¾—è°ƒåº¦ç»“æœ `scheduler_output`ã€‚

---

### 6. éªŒè¯è°ƒåº¦ç»“æœ

```python
kv_connector_metadata = scheduler_output.kv_connector_metadata
assert kv_connector_metadata is not None
assert isinstance(kv_connector_metadata, NixlConnectorMetadata)
assert len(kv_connector_metadata.requests) == 0
```

* ç¡®è®¤ `kv_connector_metadata` å­˜åœ¨ï¼Œç±»å‹ä¸º `NixlConnectorMetadata`ã€‚
* **å…³é”®ç‚¹**ï¼šå…¶ä¸­çš„ `requests` åˆ—è¡¨é•¿åº¦ä¸º 0
  â†’ è¯´æ˜ D worker **æ²¡æœ‰å‘èµ·ä»»ä½• async read**ï¼ˆå› ä¸ºæ²¡æœ‰ remote blockï¼‰ã€‚

---

### 7. éªŒè¯æ­£å¸¸è°ƒåº¦

```python
assert len(scheduler_output.scheduled_new_reqs) == 1
```

* è™½ç„¶æ²¡æœ‰è¿œç«¯ blockï¼Œä½†è¿™ä¸ªè¯·æ±‚æœ¬èº«ä»ç„¶è¦æ­£å¸¸è¿›å…¥è°ƒåº¦ã€‚
* æ‰€ä»¥ `scheduled_new_reqs` ä¸­åº”åŒ…å«è¯¥è¯·æ±‚ã€‚

---

âœ… **æ€»ç»“**ï¼š
è¿™ä¸ªæµ‹è¯•ç”¨ä¾‹ç¡®ä¿äº† **å°äºä¸€ä¸ª block çš„ prompt** ä¸ä¼šè§¦å‘æ— æ„ä¹‰çš„è¿œç«¯ KV å¼‚æ­¥è¯»å–ï¼Œä½†è¯·æ±‚ä»èƒ½è¢«è°ƒåº¦æ‰§è¡Œã€‚
æ¢å¥è¯è¯´ï¼Œè¿™æ˜¯åœ¨éªŒè¯ **prefill æ—¶ KV block è¾¹ç•Œå¤„ç†** çš„æ­£ç¡®æ€§ã€‚

---

è¦ä¸è¦æˆ‘å¸®ä½ ç”»ä¸ª **è°ƒåº¦æµç¨‹å›¾**ï¼ˆè¯·æ±‚è¿›å…¥ â†’ åˆ¤æ–­ block æ•°é‡ â†’ remote read vs regular scheduleï¼‰ï¼Ÿè¿™æ ·ä½ å¯ä»¥æ›´ç›´è§‚ç†è§£è¿™ä¸ªæµ‹è¯•éªŒè¯çš„é€»è¾‘ã€‚





# æ³¨å†Œnixl
```python
KVConnectorFactory.register_connector(
    "NixlConnector",
    "vllm.distributed.kv_transfer.kv_connector.v1.nixl_connector",
    "NixlConnector")

```





# vllmè°ƒç”¨nixlçš„è½¯ä»¶æ ˆ/åŸºç±» KVConnectorBase_V1 çš„interface

ä½ é—®çš„ **â€œvLLM è°ƒç”¨ Nixl çš„è½¯ä»¶æ ˆâ€**ï¼Œå…¶å®å°±æ˜¯åœ¨å¤§æ¨¡å‹æ¨ç†/è®­ç»ƒæ—¶ï¼ŒvLLM å¦‚ä½•æŠŠ **KV Cache ç®¡ç†** å’Œ **è¿œç«¯å†…å­˜è®¿é—®** è·Ÿ Nixl ç»“åˆèµ·æ¥ã€‚ä¸‹é¢æˆ‘ç»™ä½ æ¢³ç†ä¸€ä¸‹æ•´ä¸ªæ ˆï¼Œä» **åº”ç”¨å±‚ â†’ è°ƒåº¦å±‚ â†’ Nixl å±‚ â†’ ç¡¬ä»¶å±‚**ï¼š

---

## 1. åº”ç”¨å±‚ï¼ˆvLLMï¼‰

* **vLLM Core**ï¼šè´Ÿè´£åˆ†å¸ƒå¼æ¨ç†çš„æ‰§è¡Œï¼ˆprefillã€decodeã€sampling ç­‰ï¼‰ï¼Œæ ¸å¿ƒå°±æ˜¯ **KV Cache çš„å­˜å–**ã€‚
* **Block Manager / Scheduler**ï¼švLLM å†…éƒ¨æœ‰ä¸€ä¸ª **block-based KV cache ç®¡ç†å™¨**ï¼Œå†³å®šå“ªäº› KV block ç•™åœ¨æœ¬åœ° GPUï¼Œé«˜é¢‘è®¿é—®ï¼Œå“ªäº› block å¯ä»¥ offload åˆ°è¿œç«¯ã€‚
* å½“ prompt tokens < 1 blockï¼ˆå°±åƒä½ ç»™çš„ test caseï¼‰ï¼Œè°ƒåº¦å™¨ä¸ä¼šäº§ç”Ÿ remote block è¯·æ±‚ï¼›è€Œå½“ KV cache è¶…å‡ºæœ¬åœ°æ˜¾å­˜å®¹é‡æ—¶ï¼Œå°±ä¼šè§¦å‘ **remote block I/O**ã€‚

---

## 2. ä¸­é—´ä»¶å±‚ï¼ˆvLLM â†” Nixlï¼‰

* vLLM æŠŠ **è¿œç«¯ block è¯»/å†™** æŠ½è±¡æˆ **KV Connector**ï¼ŒNixl åªæ˜¯å…¶ä¸­çš„ä¸€ç§ backendã€‚
* è¿™é‡Œçš„ `NixlConnectorMetadata` å°±æ˜¯è°ƒåº¦å™¨è¾“å‡ºçš„å…ƒä¿¡æ¯ï¼Œå‘Šè¯‰ Nixlï¼š

  * å“ªäº› block éœ€è¦å¼‚æ­¥æ‹‰å–
  * å“ªäº› block å¯ä»¥ä¸¢å¼ƒ
  * å“ªäº› block è¦å†™å›è¿œç«¯
* è¿™ä¸ªæ¥å£å±‚å±è”½äº†åº•å±‚é€šä¿¡ç»†èŠ‚ï¼ŒvLLM åªå…³å¿ƒ â€œæˆ‘è¦ä»è¿œç«¯å–å“ªäº› blockâ€ã€‚

---

## 3. Nixl å±‚ï¼ˆMemory Disaggregation Runtimeï¼‰

* **Nixl** æä¾›äº† **è¿œç«¯å†…å­˜æ±  + é«˜é€Ÿäº’è¿** çš„æŠ½è±¡ï¼Œé€šå¸¸åŸºäº RDMAã€‚
* åŠŸèƒ½ï¼š

  * æä¾›è¿œç«¯å†…å­˜åˆ†é…ï¼ˆremote malloc/freeï¼‰
  * æ”¯æŒ block ç²’åº¦çš„ async read/write
  * ç®¡ç† **æœ¬åœ° GPU â†” DPU â†” è¿œç«¯å­˜å‚¨** çš„æ•°æ®æµ
* åœ¨ vLLM ä¸­ï¼ŒNixl å°±åƒä¸€ä¸ª **è¿œç«¯ KV Cache Server**ï¼Œä¸“é—¨å­˜æ”¾æº¢å‡ºçš„ KV blockã€‚
* ä¸€èˆ¬å®ç°ä¸Šæ˜¯åŸºäº **libibverbs / RDMA verbs** æˆ–è€… **NVIDIA GPUDirect RDMA**ï¼ŒNixl è´Ÿè´£æŠŠè¿™äº›ä½å±‚ API å°è£…æˆé«˜å±‚çš„ KV block I/Oã€‚

---

## 4. ç¡¬ä»¶å±‚

* **GPU**ï¼šè®¡ç®— + å±€éƒ¨ KV Cacheã€‚
* **NIC/DPU (å¦‚ ConnectX-6 Dx, BlueField-3)**ï¼šè´Ÿè´£ RDMA ä¼ è¾“ï¼Œç›´æ¥æŠŠè¿œç«¯ block æ‹‰åˆ° GPU å†…å­˜ã€‚
* **è¿œç«¯å†…å­˜èŠ‚ç‚¹**ï¼šå¯èƒ½æ˜¯ CPU å†…å­˜ã€å¤§å†…å­˜ GPUï¼Œæˆ–è€…ä¸“ç”¨çš„ **å†…å­˜æ± èŠ‚ç‚¹**ã€‚

---

## è½¯ä»¶æ ˆå…¨æ™¯

```
ç”¨æˆ· (LLM æ¨ç†è¯·æ±‚)
        â”‚
   vLLM Engine
        â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ BlockManagerâ”‚â”€â”€â”€è°ƒåº¦KV cacheï¼Œå†³å®šæœ¬åœ° vs è¿œç«¯
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
   vLLM KV Connector
        â”‚
   Nixl Runtime
        â”‚
   RDMA / GPUDirect / Verbs
        â”‚
   NIC / DPU (CX6, BF3)
        â”‚
   è¿œç«¯å†…å­˜æ±  (CPU DRAM / GPU HBM / CXL Mem)
```

---

## æ ¸å¿ƒè¦ç‚¹

1. **vLLM ä¸ç›´æ¥è°ƒç”¨ RDMA**ï¼Œè€Œæ˜¯é€šè¿‡ `NixlConnector` æ¥è®¿é—®è¿œç«¯ KV blockã€‚
2. **Nixl è´Ÿè´£ RDMA ç®¡ç†**ï¼Œå±è”½åº•å±‚ QPã€MRã€CQ ç­‰ç»†èŠ‚ï¼Œæš´éœ²å‡º block ç²’åº¦çš„è¯»å†™æ¥å£ã€‚
3. **DPU æ‰¿è½½ RDMA è¯·æ±‚**ï¼Œä¿è¯ GPU åœ¨éœ€è¦æ—¶å¯ä»¥ç›´æ¥ä»è¿œç«¯æ‹‰æ•°æ®ï¼Œä¸éœ€è¦ CPU ä»‹å…¥ã€‚
4. **è°ƒåº¦é€»è¾‘åœ¨ vLLM**ï¼Œ**æ•°æ®é€šè·¯åœ¨ Nixl**ã€‚

---

è¦ä¸è¦æˆ‘ç»™ä½ ç”»ä¸€ä¸ª **è¯·æ±‚ä» vLLM åˆ° Nixl çš„æ•°æ®æµæ—¶åºå›¾**ï¼ˆæ¯”å¦‚ prefill â†’ schedule â†’ Nixl async read â†’ DPU â†’ GPUï¼‰ï¼Ÿè¿™æ ·æ¯”è½¯ä»¶æ ˆåˆ†å±‚æ›´ç›´è§‚ã€‚




# äº¤äº’æ—¶åºå›¾
å¥½ï¼Œé‚£æˆ‘ç»™ä½ ç”»ä¸€ä¸ª **æ—¶åºå›¾**ï¼Œå±•ç¤º vLLM åœ¨ **éœ€è¦è¿œç«¯ KV block æ—¶**ï¼Œè°ƒç”¨ Nixl çš„å®Œæ•´æ•°æ®æµï¼š

---

## ğŸ“œ vLLM â†” Nixl â†” ç¡¬ä»¶ çš„æ—¶åºæµç¨‹

```
ç”¨æˆ·è¯·æ±‚ (Prompt / Decode)
        â”‚
        â–¼
   vLLM Scheduler
        â”‚
        â”‚ åˆ¤æ–­ï¼šæœ¬åœ°æ˜¾å­˜è¶³å¤Ÿï¼Ÿ
        â”‚
        â”œâ”€ æ˜¯ â†’ ç›´æ¥è°ƒåº¦ (èµ°GPUæœ¬åœ°KV Cache)
        â”‚
        â””â”€ å¦ â†’ éœ€è¦è¿œç«¯block
              â”‚
              â–¼
       NixlConnector
              â”‚
              â”‚ å‘èµ· async read/write è¯·æ±‚ (block_id)
              â–¼
         Nixl Runtime
              â”‚
              â”‚ è½¬æ¢ä¸º RDMA verbs (ibv_post_send/recv)
              â–¼
        NIC / DPU (CX6-Dx / BF3)
              â”‚
              â”‚ é€šè¿‡ RDMA ç›´æ¥ä¼ è¾“ (GPU RDMA / GPUDirect)
              â–¼
       è¿œç«¯å†…å­˜æ±  (CPU DRAM / GPU HBM / CXL Mem)
```

---

## ğŸ”„ æ›´è¯¦ç»†çš„ **äº¤äº’æ—¶åº (Async Read ç¤ºä¾‹)**

```
ç”¨æˆ·          vLLM-Scheduler   NixlConnector   Nixl Runtime    NIC/DPU    è¿œç«¯å†…å­˜
 â”‚                  â”‚               â”‚              â”‚             â”‚           â”‚
 â”‚ è¯·æ±‚æ¨ç†         â”‚               â”‚              â”‚             â”‚           â”‚
 â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚               â”‚              â”‚             â”‚           â”‚
 â”‚                  â”‚ è°ƒåº¦è¯·æ±‚      â”‚              â”‚             â”‚           â”‚
 â”‚                  â”‚â”€â”€â”€ç”Ÿæˆblock_idåˆ—è¡¨â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚             â”‚           â”‚
 â”‚                  â”‚               â”‚ å‘èµ·async read             â”‚           â”‚
 â”‚                  â”‚               â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚             â”‚           â”‚
 â”‚                  â”‚               â”‚              â”‚ è½¬ä¸ºibv_post_send       â”‚
 â”‚                  â”‚               â”‚              â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚           â”‚
 â”‚                  â”‚               â”‚              â”‚             â”‚ RDMAè¯»è¿œç«¯block
 â”‚                  â”‚               â”‚              â”‚             â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
 â”‚                  â”‚               â”‚              â”‚             â”‚           â”‚
 â”‚                  â”‚               â”‚              â”‚             â”‚ blockæ•°æ®è¿”å›
 â”‚                  â”‚               â”‚              â”‚             â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
 â”‚                  â”‚               â”‚              â”‚ CQé€šçŸ¥å®Œæˆ  â”‚           â”‚
 â”‚                  â”‚               â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚             â”‚           â”‚
 â”‚                  â”‚ KV blockåˆ°GPU â”‚              â”‚             â”‚           â”‚
 â”‚                  â”‚               â”‚              â”‚             â”‚           â”‚
 â”‚ ç»§ç»­æ¨ç†         â”‚               â”‚              â”‚             â”‚           â”‚
 â”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚               â”‚              â”‚             â”‚           â”‚
```

---

## ğŸš€ å…³é”®ç‚¹

* **Scheduler**ï¼šå†³å®šæ˜¯å¦è§¦å‘è¿œç«¯è¯»ï¼ˆblock ç²’åº¦ï¼‰ã€‚
* **NixlConnector**ï¼šæŠ½è±¡æ¥å£ï¼ŒæŠŠ â€œblock\_idâ€ è¯·æ±‚ä¸‹å‘åˆ° Nixl runtimeã€‚
* **Nixl Runtime**ï¼šå°è£… RDMA verbsï¼ˆ`ibv_post_send`ã€`ibv_post_recv`ã€`ibv_poll_cq`ï¼‰ã€‚
* **NIC/DPU**ï¼šæ‰§è¡Œ RDMA æ“ä½œï¼Œç›´æ¥æ¬è¿æ•°æ®ã€‚
* **è¿œç«¯å†…å­˜æ± **ï¼šå¯èƒ½æ˜¯ CPU å¤§å†…å­˜ã€å¦ä¸€å° GPU HBMï¼Œæˆ– CXL å†…å­˜ã€‚

---

è¦ä¸è¦æˆ‘å¸®ä½ æŠŠè¿™ä¸ª **äº¤äº’æ—¶åºå›¾ç”»æˆ ASCII ä¹‹å¤–çš„â€œæ¡†å›¾+ç®­å¤´å›¾â€ï¼ˆåƒè®ºæ–‡é‡Œçš„æ•°æ®æµå›¾ï¼‰**ï¼Ÿè¿™æ ·æ›´ç›´è§‚ï¼Œèƒ½çœ‹å‡º GPU â†” DPU â†” è¿œç«¯å†…å­˜çš„è·¯å¾„ã€‚







# vllmä¸­çš„nixl

ä½ é—®åˆ° **nixl åœ¨ vLLM ä¸­çš„å®ç°**ï¼Œæˆ‘æ¥å¸®ä½ æ¢³ç†ä¸€ä¸‹ã€‚

---

### 1. èƒŒæ™¯

* **vLLM** æ˜¯ä¸€ä¸ªé«˜æ•ˆæ¨ç†å¼•æ“ï¼Œæ ¸å¿ƒä¼˜åŒ–ç‚¹åœ¨äº **PagedAttention**ã€è°ƒåº¦å™¨ã€ä»¥åŠé«˜æ•ˆçš„ KV Cache ç®¡ç†ã€‚
* ä¸ºäº†è¿›ä¸€æ­¥æå‡åˆ†å¸ƒå¼è®­ç»ƒ/æ¨ç†ä¸­çš„é€šä¿¡æ•ˆç‡ï¼ŒvLLM å¼•å…¥äº† **nixl**ï¼ˆNVIDIA Infiniband eXtensions Layer çš„ç¼©å†™ï¼Œå¯ä»¥ç†è§£ä¸ºä¸€ä¸ª *RDMA é€šä¿¡æŠ½è±¡å±‚*ï¼‰ã€‚
* nixl çš„ç›®çš„ï¼šåœ¨ vLLM ä¸­å±è”½åº•å±‚ **verbs API**ï¼ˆ`ibv_post_send`ã€`ibv_poll_cq` ç­‰ï¼‰çš„å¤æ‚æ€§ï¼Œæä¾›ä¸€ä¸ªé«˜æ€§èƒ½ã€ç»Ÿä¸€æ¥å£çš„ **é€šä¿¡å±‚**ï¼ŒåŒæ—¶å…¼å®¹ GPU Direct RDMAã€‚

---

### 2. nixl çš„è®¾è®¡æ€è·¯

å¯ä»¥çœ‹æˆæ˜¯ **vLLM çš„ç½‘ç»œæ ˆå®ç°**ï¼Œå’Œ NCCL åœ¨ collective é€šä¿¡ä¸Šçš„è§’è‰²æœ‰ç‚¹ç±»ä¼¼ï¼Œä½†æ›´è½»é‡ã€æ›´é¢å‘ **point-to-point å¼‚æ­¥ä¼ è¾“**ã€‚

* **æŠ½è±¡å±‚**
  nixl å°†åº•å±‚çš„ QPã€CQã€MR ç­‰æŠ½è±¡æˆâ€œè¿æ¥â€å’Œâ€œå†…å­˜åŒºåŸŸâ€ï¼Œæä¾›é¢å‘æ¶ˆæ¯/ç‰‡æ®µçš„æ¥å£ã€‚

* **é›¶æ‹·è´**
  nixl åœ¨ GPU ä¸Šæ³¨å†Œå†…å­˜ï¼Œç›´æ¥èµ° GPUDirect RDMAï¼Œä¸éœ€è¦ CPU å‚ä¸æ•°æ®æ¬è¿ã€‚

* **å¼‚æ­¥è°ƒåº¦**
  nixl çš„ `send`/`recv` æ¥å£æ˜¯å¼‚æ­¥çš„ï¼Œé…åˆ vLLM å†…éƒ¨çš„ worker pool / schedulerï¼Œé¿å… blockã€‚
  å®ƒä¼šå…ˆå†™å…¥ `WQE`ï¼ˆwork queue entryï¼‰ï¼Œå†ç”± `completion queue` é©±åŠ¨å›è°ƒã€‚

* **é«˜å¹¶å‘ QP ç®¡ç†**
  vLLM çš„åœºæ™¯ä¸‹ï¼Œä¸€ä¸ªèŠ‚ç‚¹å¯èƒ½è¦å’Œå¤šä¸ª peer å»ºç«‹è¿æ¥ï¼Œnixl æä¾›äº† QP å¤ç”¨ / è¿æ¥æ± ï¼Œå‡å°‘ QP çˆ†ç‚¸ã€‚

---

### 3. åœ¨ vLLM ä¸­çš„ä½œç”¨

* **å‚æ•°/æ¿€æ´»åˆ†ç‰‡ä¼ è¾“**
  å½“ vLLM åšåˆ†å¸ƒå¼æ¨ç†æ—¶ï¼Œéœ€è¦åœ¨ä¸åŒ rank ä¹‹é—´ä¼ è¾“ KV Cacheã€è¾“å…¥ token embedding ç­‰ã€‚
  nixl è´Ÿè´£è¿™äº›è·¨èŠ‚ç‚¹æ•°æ®çš„ä¼ è¾“ã€‚

* **ç»“åˆè°ƒåº¦å™¨**
  vLLM çš„è°ƒåº¦å™¨ (scheduler) åœ¨å†³å®šæ‰§è¡Œå“ªä¸ª request çš„æ—¶å€™ï¼Œä¼šè°ƒç”¨ nixl çš„æ¥å£æ¥æ”¶/å‘è¿œç«¯ blockï¼Œé¿å…é˜»å¡æœ¬åœ°è®¡ç®—ã€‚

* **WorkerPool + nixl**
  ä½ ä¹‹å‰è´´çš„ `WorkerPool` ä»£ç ï¼Œå°±æ˜¯åœ¨ç®¡ç†å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—ã€‚nixl æä¾› `async read/write`ï¼ŒWorkerPool æŠŠå®ƒå’Œ request lifecycle ç»‘å®šã€‚

---

### 4. æ ¸å¿ƒå®ç°ç‚¹

ä» vLLM ä»£ç æ¥çœ‹ï¼Œnixl ä¸»è¦å®ç°äº†å‡ ä¸ªæ¨¡å—ï¼š

1. **åˆå§‹åŒ– (context)**

   * æ‰“å¼€ RDMA device (`ibv_open_device`)
   * åˆ›å»º PDã€CQã€QP
   * æ³¨å†Œ host/GPU å†…å­˜ (`ibv_reg_mr`)

2. **è¿æ¥ç®¡ç†**

   * é€šè¿‡ TCP/IB bootstrap äº¤æ¢ QP ä¿¡æ¯ (LID, QPN, PSN)
   * ä¿®æ”¹ QP çŠ¶æ€ (INIT â†’ RTR â†’ RTS)

3. **æ•°æ®æ”¶å‘**

   * `nixl_post_send()` â†’ å°è£… `ibv_post_send`
   * `nixl_poll_cq()` â†’ poll å®Œæˆé˜Ÿåˆ—ï¼Œè§¦å‘å›è°ƒ
   * æ”¯æŒ `RDMA_READ/WRITE`ï¼Œåœ¨è·¨èŠ‚ç‚¹ KV cache æ‹‰å–æ—¶ç”¨å¾—å¤š

4. **é”™è¯¯å¤„ç† & å¼‚å¸¸æ¢å¤**

   * æ£€æŸ¥ QP/CQ çŠ¶æ€
   * é‡åˆ°ç½‘ç»œé”™è¯¯æ—¶å¿«é€Ÿé‡è¿/abort

---

### 5. ä¸ºä»€ä¹ˆä¸ç”¨ NCCLï¼Ÿ

* **NCCL é€‚åˆ collective** (all-reduce, all-gather ç­‰)ï¼Œä½†æ˜¯ point-to-pointã€å¼‚æ­¥ granularity ä¸å¤Ÿçµæ´»ã€‚
* vLLM çš„æ•°æ®ä¼ è¾“æ›´åƒæ˜¯â€œæ‹‰å–è¿œç«¯ KV å—â€ï¼Œé‡çº§å°è€Œé¢‘ç¹ï¼Œç”¨ RDMA verbs æ›´é«˜æ•ˆã€‚
* nixl å°±æ˜¯åšäº† NCCL æ²¡æœ‰è¦†ç›–çš„ **è½»é‡ RDMA é€šä¿¡å±‚**ã€‚

---

### 6. æ€»ç»“

åœ¨ vLLM ä¸­ï¼Œ**nixl å°±æ˜¯ä¸€ä¸ª RDMA é€šä¿¡æŠ½è±¡å±‚**ï¼Œè´Ÿè´£ï¼š

* å»ºç«‹è¿æ¥ã€æ³¨å†Œæ˜¾å­˜
* å¼‚æ­¥æ”¶å‘æ•°æ®
* ä¸è°ƒåº¦å™¨ã€worker pool é…åˆï¼Œä¿è¯ request lifecycle å†…çš„ KV cache/å‚æ•°èƒ½åœ¨ä¸åŒèŠ‚ç‚¹ä¹‹é—´é«˜æ•ˆæµåŠ¨

ä¸€å¥è¯æ€»ç»“ï¼š
**nixl æ˜¯ vLLM çš„â€œç½‘ç»œé©±åŠ¨å±‚â€ï¼Œä¸“é—¨é’ˆå¯¹å¤§æ¨¡å‹æ¨ç†åœºæ™¯å®šåˆ¶ï¼Œæ¯” NCCL æ›´çµæ´»ï¼Œæ¯”ç›´æ¥ verbs æ›´æ˜“ç”¨ã€‚**

---

è¦ä¸è¦æˆ‘å¸®ä½ ç”»ä¸€ä¸ª **â€œvLLM è°ƒåº¦å™¨ â€“ WorkerPool â€“ nixl â€“ RDMA deviceâ€ çš„ç»“æ„å›¾**ï¼Ÿè¿™æ ·èƒ½ç›´è§‚çœ‹æ¸… nixl çš„ä½ç½®ã€‚


åœ¨ vLLM é‡Œï¼Œ**nixl** å¯ä»¥ç†è§£ä¸ºä¸€ä¸ªä¸“é—¨ä¸ºå¤§æ¨¡å‹æ¨ç†åœºæ™¯åšçš„ **RDMA é€šä¿¡æŠ½è±¡å±‚**ã€‚å®ƒçš„è§’è‰²å¤§æ¦‚æ˜¯ï¼š

* **å±è”½åº•å±‚ verbs**ï¼šå°è£… `ibv_post_send` / `ibv_poll_cq` ç­‰æ¥å£ï¼Œç»Ÿä¸€æˆé¢å‘æ¶ˆæ¯/å†…å­˜å—çš„ APIã€‚
* **é«˜æ•ˆä¼ è¾“**ï¼šæ”¯æŒæ˜¾å­˜æ³¨å†Œï¼Œèµ° GPUDirect RDMAï¼Œé›¶æ‹·è´ã€‚
* **å¼‚æ­¥æ¨¡å‹**ï¼šsend/recv éƒ½æ˜¯å¼‚æ­¥çš„ï¼Œå’Œ vLLM çš„è°ƒåº¦å™¨ã€worker pool å¯¹æ¥ï¼Œé¿å…é˜»å¡ã€‚
* **è¿æ¥ç®¡ç†**ï¼šå»ºç«‹ QPã€CQï¼Œç»´æŠ¤è¿æ¥æ± ï¼Œå‡å°‘ QP çˆ†ç‚¸é—®é¢˜ã€‚
* **ä¸»è¦ç”¨é€”**ï¼šè·¨èŠ‚ç‚¹ä¼ è¾“ KV cache / æ¿€æ´» / embedding ç­‰ï¼Œå¸¸ç”¨ `RDMA_READ/WRITE` æ‹‰å–è¿œç«¯æ•°æ®ã€‚

ç›¸æ¯” NCCLï¼Œnixl æ›´è½»é‡ã€çµæ´»ï¼š

* NCCL åå‘ collectiveï¼ˆall-reduce, all-gatherï¼‰ï¼›
* vLLM çš„å…¸å‹éœ€æ±‚æ˜¯â€œæŒ‰éœ€æ‹‰å–è¿œç«¯ KV blockâ€ï¼Œé‡å°è€Œé¢‘ç¹ï¼Œæ›´é€‚åˆ RDMA verbsã€‚

ä¸€å¥è¯æ€»ç»“ï¼š
ğŸ‘‰ **nixl å°±æ˜¯ vLLM çš„ç½‘ç»œé©±åŠ¨å±‚ï¼Œè´Ÿè´£èŠ‚ç‚¹é—´é«˜æ•ˆçš„æ•°æ®ä¼ è¾“ï¼Œæ¯” NCCL çµæ´»ï¼Œæ¯”ç›´æ¥å†™ verbs ç®€æ´ã€‚**

è¦ä¸è¦æˆ‘ç»™ä½ ç”»ä¸ª **è°ƒåº¦å™¨ â€“ WorkerPool â€“ nixl â€“ RDMA device** çš„æ¡†å›¾ï¼Œè®© nixl åœ¨ vLLM æ¶æ„é‡Œçš„ä½ç½®æ›´ç›´è§‚ï¼Ÿ





# è§£è¯»å…¶è¿æ¥å™¨å®ç° nixl_connector.py ä¸ŠåŠéƒ¨åˆ†

ä¸‹é¢æŒ‰ä½ è´´çš„è¿™æ®µä»£ç ï¼ŒæŠŠ **vLLM çš„ NixlConnector** å…³é”®ç»“æ„ã€è°ƒåº¦/å·¥ä½œä¸¤ç«¯çš„èŒè´£ã€å…ƒæ•°æ®æµè½¬ã€ä»¥åŠå®ƒå¦‚ä½•å†³å®šâ€œè¯¥ä¸è¯¥å»æ‹‰å–è¿œç«¯ KV å—â€è¿™å‡ ä»¶äº‹è®²æ¸…æ¥šã€‚é‡ç‚¹ä¼šç»“åˆä½ ä¹‹å‰æè¿‡çš„åœºæ™¯ï¼ˆprompt < block æ—¶ P worker å‘é€ empty `remote_block_ids`ã€D worker ä¸åº”å‘èµ·å¼‚æ­¥ RDMA è¯»å–ï¼‰ã€‚

---

# æ€»è§ˆï¼šNixl åœ¨ vLLM é‡Œçš„è½ç‚¹

* è¿™ä¸€ç»„ç±»æŠŠ **nixl RDMA é€šé“** æ’è¿›äº† vLLM çš„ **KV è¿ç§»æ¥å£ï¼ˆKVConnectorBase\_V1ï¼‰**ã€‚
* ä»£ç åˆ†ä¸¤ä¾§ï¼š

  * **Scheduler ä¾§**ï¼ˆ`NixlConnectorScheduler`ï¼‰ï¼šå†³å®šâ€œå“ªäº›è¯·æ±‚éœ€è¦ä»è¿œç«¯æ‹‰å–/ä¿å­˜ KVâ€ï¼ŒæŠŠè¿™äº›å†³ç­–æ‰“åŒ…æˆ **ConnectorMetadata** äº¤ç»™ Workerã€‚
  * **Worker ä¾§**ï¼ˆ`NixlConnectorWorker`ï¼Œå®ç°ä¸åœ¨ä½ è¿™æ®µé‡Œï¼‰ï¼šçœŸæ­£å»æ³¨å†Œ KV æ˜¾å­˜ã€å»ºç«‹ RDMA è¿æ¥ã€å‘èµ· `RDMA_READ/WRITE`ã€ä»¥åŠå¯é€‰çš„ Host ç¼“å†²æ‹·è´ã€‚
* **ZeroMQ ä¾§ä¿¡é“**ï¼ˆ`side_channel_host/port`ï¼‰ä»…ç”¨äºäº¤æ¢ **Agent/å†…å­˜åœ°å€ç­‰å…ƒä¿¡æ¯**ï¼›çœŸæ­£çš„æ•°æ®ä¼ è¾“èµ° RDMAï¼ˆnixlï¼‰ã€‚

---

# å…³é”®å¯¹è±¡ä¸å­—æ®µ

### 1) æ‡’åŠ è½½ nixl

```python
try:
    from nixl._api import nixl_agent as NixlWrapper
except ImportError:
    NixlWrapper = None
```

* é¿å…åœ¨æ²¡å¯ç”¨ nixl æ—¶å¼ºè¡ŒåŠ è½½ RDMA ç»‘å®šã€‚

### 2) æ”¯æŒçš„ xPU ä¸ç¼“å†²è®¾å¤‡

```python
_NIXL_SUPPORTED_XPUS = {
    "cuda": ("cuda", ),
    "tpu": ("cpu", ),
}
```

* CUDA ä¸‹æ”¯æŒç›´æ¥ç”¨ **CUDA ç¼“å†²**ï¼ˆGPUDirect RDMAï¼‰ï¼›TPU åˆ™è½å› **CPU ç¼“å†²**ã€‚

### 3) `NixlAgentMetadata`

```python
class NixlAgentMetadata(msgspec.Struct):
    engine_id: str
    agent_metadata: bytes
    kv_caches_base_addr: list[int]
    num_blocks: int
    block_len: int
    attn_backend_name: str
    kv_cache_layout: str
```

* é€šè¿‡ **ZMQ ä¾§ä¿¡é“** ä¼ è¾“ç»™å¯¹ç«¯ï¼ˆæˆ– workerï¼‰çš„ **â€œæ¡æ‰‹+å¸ƒå±€â€å…ƒæ•°æ®**ï¼š

  * `agent_metadata`ï¼šæ¥è‡ª `NixlWrapper`ï¼Œç”¨äº RDMA å±‚å»ºç«‹è¿æ¥/äº¤æ¢ QP ä¹‹ç±»çš„ä¿¡æ¯ã€‚
  * `kv_caches_base_addr / num_blocks / block_len / kv_cache_layout`ï¼šå‘Šè¯‰å¯¹ç«¯ **KV cache åœ¨å†…å­˜/æ˜¾å­˜çš„å¸ƒå±€ä¸åŸºå€**ï¼Œä¾¿äº RDMA ç›´æ¥å®šä½å—ã€‚

### 4) æ¯ä¸ªè¯·æ±‚çš„å…ƒæ•°æ® `ReqMeta`

```python
@dataclass
class ReqMeta:
    local_block_ids: list[int]
    remote_block_ids: list[int]
    remote_host: str
    remote_port: int
    remote_engine_id: str
    tp_size: int
```

* ä¸€æ¬¡è¯·æ±‚åœ¨ **æœ¬åœ°/è¿œç«¯** å„è‡ªæ¶‰åŠå“ªäº› KV å—ï¼Œä»¥åŠå¯¹ç«¯çš„ **engine\_id / åœ°å€**ã€‚
* `remote_block_ids` å¯èƒ½ä¸ºç©ºï¼ˆå…¸å‹ï¼š**prompt < block**ï¼Œæ²¡æœ‰éœ€è¦ä»è¿œç«¯æ‹‰çš„å—ï¼‰ã€‚

### 5) `NixlConnectorMetadata`

* è¿™æ˜¯ **Schedulerâ†’Worker çš„æ¡¥**ï¼ŒæŠŠè¦åšçš„äº‹æ±‡æ€»æˆä¸‰ä¸ªå“ˆå¸Œè¡¨ï¼š

  * `reqs_to_recv`ï¼šéœ€è¦ä»è¿œç«¯ **æ‹‰å–** KV çš„è¯·æ±‚
  * `reqs_to_save`ï¼šéœ€è¦æŠŠæœ¬åœ° KV **ä¿å­˜**ï¼ˆå†™å›å¯¹ç«¯/ä¸»æœºï¼‰çš„è¯·æ±‚
  * `reqs_to_send`ï¼šéœ€è¦ **å‘é€** çš„è¯·æ±‚ï¼ˆå¸¦è¿‡æœŸæ—¶é—´ï¼‰
* æ¥å£ `add_new_req(...)` é‡Œ `load_remote_cache` ä¸ `save_to_host` äº’æ–¥ï¼Œå†³å®šæ”¾è¿› `recv` è¿˜æ˜¯ `save`ã€‚

---

# NixlConnector æœ¬ä½“ä¸ KV å¸ƒå±€

### 1) è§’è‰²æ‹†åˆ†

```python
if role == KVConnectorRole.SCHEDULER:
    self.connector_scheduler = NixlConnectorScheduler(...)
elif role == KVConnectorRole.WORKER:
    self.connector_worker = NixlConnectorWorker(...)
```

* ä¸€ä¸ªè¿›ç¨‹ä»¥ **è°ƒåº¦å™¨** æˆ– **å·¥ä½œè¿›ç¨‹** èº«ä»½åˆ›å»ºå¯¹åº”ç«¯çš„ connectorã€‚

### 2) KV Cache å¸ƒå±€è¦æ±‚

```python
@classmethod
def get_required_kvcache_layout(cls, vllm_config):
    if vllm_config.model_config.use_mla:
        return None
    logger.info_once("... KV cache layout to HND for better xfer performance.")
    return "HND"
```

* è‹¥ **æœªä½¿ç”¨ MLA**ï¼Œå¼ºåˆ¶å°† KV å¸ƒå±€è®¾ä¸º **`HND`**ï¼ˆæœ‰åˆ©äº RDMA **æ•´å—ç›´è¾¾ã€å‡å°‘ stride/æ•£å¸ƒ**ï¼‰ã€‚
* å«ä¹‰ï¼šWorker æ³¨å†Œçš„ KV ç¼“å†²ä»¥è¿™ç§å¸ƒå±€æš´éœ²ç»™å¯¹ç«¯ï¼Œ`num_blocks/block_len/base_addr` éƒ½ä¸ä¹‹åŒ¹é…ã€‚

---

# Scheduler ä¾§çš„æ ¸å¿ƒé€»è¾‘

### åˆå§‹åŒ–

```python
self.side_channel_host = envs.VLLM_NIXL_SIDE_CHANNEL_HOST
self.side_channel_port = (
    envs.VLLM_NIXL_SIDE_CHANNEL_PORT
    + dp_rank * tp_size
)
self.use_host_buffer = (kv_buffer_device == "cpu")
```

* **ZMQ ä¾§ä¿¡é“ç«¯å£** = åŸºç¡€ç«¯å£ + `data_parallel_rank * tensor_parallel_size`ï¼Œé¿å…å¤šå¹¶è¡Œåº¦ä¸‹å†²çªã€‚
* å¦‚æœ KV ç¼“å†²è®¾å¤‡æ˜¯ `cpu`ï¼ŒWorker ä¾§ä¼šèµ° **host ç¼“å†²** ç®¡çº¿ã€‚

### 1) å†³å®šèƒ½â€œé¢å¤–åŒ¹é…â€çš„è¿œç«¯ tokenï¼š`get_num_new_matched_tokens(...)`

æ ¸å¿ƒç”¨é€”ï¼š**è¿œç«¯é¢„å¡«ï¼ˆremote prefillï¼‰** åœºæ™¯ï¼Œç»Ÿè®¡â€œè¿˜èƒ½ä»è¿œç«¯ KV ç›´æ¥åŠ è½½å¤šå°‘ tokenï¼ˆæ— éœ€æœ¬åœ°å†ç®—ï¼‰â€ï¼Œå¹¶å‘ŠçŸ¥æ˜¯å¦ **å¼‚æ­¥åŠ è½½**ã€‚

ä¼ªä»£ç ï¼ˆä½ è´´çš„å¼€å¤´ç‰‡æ®µå°±è¿™ä¹ˆå¹²çš„ï¼‰ï¼š

```python
if params and params.get("do_remote_prefill"):
    count = len(request.prompt_token_ids) - num_computed_tokens
    if count > 0:
        return (count, True)   # è¿˜èƒ½åŠ è½½è¿™ä¹ˆå¤šï¼Œå¹¶ä¸”ä¼šå¼‚æ­¥æ‹‰å–
```

> âœ… **ä¸ä½ æåˆ°çš„ â€œprompt < blockâ€ åœºæ™¯å¯¹é½**ï¼š
> å¦‚æœ `remote_block_ids` ä¸ºç©ºï¼ˆæ„å‘³ç€è¿œç«¯å¹¶æ²¡æœ‰å¯æ‹‰çš„å—ï¼‰ï¼Œé‚£ä¹ˆ `count` ä¼šå›è½åˆ° 0 æˆ–è€…åç»­ `update_state_after_alloc` ä¸ä¼šæŠŠè¿™ä¸ªè¯·æ±‚å¡è¿› `reqs_to_recv`ï¼Œ**D/Worker ç«¯ä¹Ÿå°±ä¸ä¼šå‘èµ· RDMA è¯»å–**ã€‚

### 2) `update_state_after_alloc(request, blocks, num_external_tokens)`

* åœ¨ **åˆ†é…å®Œæœ¬åœ° KV å—** ä¹‹åï¼Œæ ¹æ®è¯·æ±‚çš„ `kv_transfer_params` ä¸ `blocks` çš„å¯¹åº”å…³ç³»ï¼Œ**æŠŠéœ€è¦æ‹‰å–/ä¿å­˜çš„è¯·æ±‚ç¼–å· + å— id** å¡«è¿›ï¼š

  * `self._reqs_need_recv[req_id] = (request, local_block_ids)`
  * `self._reqs_need_save[req_id] = (request, local_block_ids)`
  * ä»¥åŠ `self._reqs_need_send[req_id] = expire_time`

ï¼ˆå®ç°ç»†èŠ‚åœ¨æœ¬æ–‡ä»¶åç»­æˆ–åŒç›®å½•å…¶ä»–æ–‡ä»¶é‡Œï¼Œè¿™é‡Œä½ è´´çš„ç‰‡æ®µè¿˜æ²¡åˆ°ï¼Œä½†æ¥å£è¯­ä¹‰æ˜¯æ˜ç¡®çš„ã€‚ï¼‰

### 3) `build_connector_meta(scheduler_output) -> NixlConnectorMetadata`

* æŠŠ `_reqs_need_recv/_reqs_need_save/_reqs_need_send` æ±‡æ€»æ‰“åŒ…æˆ **`NixlConnectorMetadata`**ï¼Œäº¤ç»™ Workerï¼ˆé€šè¿‡ vLLM çš„è°ƒåº¦/æ‰§è¡Œè·¯å¾„ä¼ ä¸‹å»ï¼‰ã€‚

### 4) `request_finished(request, block_ids)`

* è¯·æ±‚ç»“æŸæ—¶ï¼Œå†³å®šæ˜¯å¦éœ€è¦æŠŠ **æœ¬åœ° KV å›å†™/ä¿ç•™**ï¼ˆä¾‹å¦‚ä¾›åç»­ remote prefill å¤ç”¨ï¼‰ï¼Œå¹¶è¿”å›ç»™ä¸Šå±‚â€œæ˜¯å¦éœ€è¦ä¿å­˜â€ä»¥åŠå¯èƒ½çš„é¢å¤–å‚æ•°ã€‚

---

# Worker ä¾§ï¼ˆä»æ¥å£èƒ½çœ‹å‡ºçš„èŒè´£ï¼‰

> Worker å…·ä½“å®ç°ä¸åœ¨ä½ è´´çš„æ®µè½é‡Œï¼Œä½†ä»è¿™äº›æ–¹æ³•èƒ½çœ‹æ¸…å®ƒå¹²ä»€ä¹ˆï¼š

### 1) æ³¨å†Œ KV æ˜¾å­˜

```python
def register_kv_caches(self, kv_caches: dict[str, torch.Tensor]):
    # å…¸å‹åšæ³•ï¼šç”¨ nixl/GDR æ³¨å†Œæ˜¾å­˜ä¸º RDMA MR
```

### 2) å¯é€‰çš„ host ç¼“å†²æ‹·è´èƒ½åŠ›

```python
def set_host_xfer_buffer_ops(self, copy_operation: CopyBlocksOp)
```

* å½“ `kv_buffer_device == "cpu"` æ—¶ï¼ŒWorker ç”¨ä½ ä¼ å…¥çš„ `copy_blocks` å›è°ƒåœ¨ **GPU â†” CPU** ä¹‹é—´åšå—çº§æ‹·è´ï¼ˆæ¯”å¦‚ä¿å­˜åˆ°ä¸»æœºå†…å­˜ï¼‰ã€‚

### 3) å¯åŠ¨è¿œç«¯æ‹‰å–

```python
def start_load_kv(self, forward_context: ForwardContext, **kwargs):
    # è¯»å–ä¸Šä¸€æ­¥ Scheduler æ‰“åŒ…çš„ NixlConnectorMetadata
    # å¯¹æ¯ä¸ª reqs_to_recv[req_id]ï¼š
    #   - é€šè¿‡ ZMQ è·å–å¯¹ç«¯ NixlAgentMetadataï¼ˆbase_addrã€layoutï¼‰
    #   - ç”± NixlWrapper å‘èµ· RDMA_READï¼ŒæŠŠè¿œç«¯ block ç›´æ¥ dma åˆ°æœ¬åœ° KV å—
```

### 4) æŸ¥è¯¢å®Œæˆæ€

```python
def get_finished(self, finished_req_ids: set[str]) -> (set[str], set[str])
```

* è¿”å› **å®Œæˆæ¥æ”¶** ä¸ **å®Œæˆå‘é€/ä¿å­˜** çš„è¯·æ±‚é›†åˆï¼Œä¾›å¼•æ“ä¸Šå±‚æ¨è¿›è°ƒåº¦ã€‚

### 5) ä¿å­˜ KVï¼ˆhost ç¼“å†²è·¯å¾„ï¼‰

```python
def wait_for_save(self):
    if self.use_host_buffer and self.copy_blocks:
        self.save_kv_to_host(self._connector_metadata)
```

* è‹¥é…ç½®ä¸º **CPU ç¼“å†²**ï¼Œåœ¨è¿™é‡Œè§¦å‘ **æ˜¾å­˜â†’å†…å­˜** çš„åˆ†å—æ‹·è´ä¸ï¼ˆå¯èƒ½çš„ï¼‰RDMA å‘é€ã€‚

> å¦å¤–å¯ä»¥æ³¨æ„åˆ°ï¼š
>
> ```python
> def wait_for_layer_load(self, layer_name): pass
> def save_kv_layer(...): pass
> ```
>
> * Nixl è·¯å¾„ä¸‹ä¸åš **æŒ‰å±‚** çš„ä¿å­˜/åŠ è½½ï¼Œè€Œæ˜¯æŒ‰ **å—** ç²’åº¦ä¸€æ¬¡æ€§å¤„ç†ï¼Œè¿™ä¸å®ƒçš„ RDMA ç›´è¾¾è®¾è®¡ç›¸ç¬¦ã€‚

---

# å…³äº â€œprompt < blockâ€ çš„å…·ä½“è¡Œä¸º

* å½“ **prompt token æ•° < block\_size**ï¼Œé€šå¸¸ **ä¸ä¼šäº§ç”Ÿä»»ä½• `remote_block_ids`**ï¼ˆè¿œç«¯æ²¡æœ‰å®Œæ•´å—å¯å¤ç”¨ï¼‰ã€‚
* è¿™ä¼šå¯¼è‡´ï¼š

  1. `get_num_new_matched_tokens(...)` è¿”å› â€œå¯åŠ è½½ token æ•°ä¸º 0 / ä¸éœ€è¦å¼‚æ­¥åŠ è½½â€ï¼Œæˆ–
  2. `update_state_after_alloc(...)` **ä¸æŠŠè¯¥è¯·æ±‚å¡è¿›** `_reqs_need_recv`ï¼Œ
  3. `build_connector_meta(...)` é‡Œ **`reqs_to_recv` ä¸å«è¯¥è¯·æ±‚**ï¼Œ
  4. Worker ä¾§çš„ `start_load_kv(...)` è‡ªç„¶ **ä¸ä¼šå‘èµ· RDMA\_READ**ã€‚
* è¿™æ­£æ˜¯ä½ æåˆ°çš„æœŸæœ›è¡Œä¸ºï¼šâ€œ**D worker ä¸åº”è°ƒåº¦å¼‚æ­¥è¯»**â€ã€‚

---

# å°ç»“ï¼ˆæŠŠä¸»çº¿ä¸²ä¸€ä¸‹ï¼‰

1. **Scheduler** åˆ¤å®šè¿™ä¸ªè¯·æ±‚æ˜¯å¦è¦â€œè¿œç«¯é¢„å¡«/æ‹‰å—â€ï¼Œå¹¶è®°å½•éœ€è¦æ‹‰å–/ä¿å­˜çš„ **å— id åˆ—è¡¨**ã€‚
2. æŠŠè¿™äº›å†³ç­–æ‰“åŒ…æˆ **`NixlConnectorMetadata`** ç»™ **Worker**ã€‚
3. **Worker** é€šè¿‡ **ZMQ** äº¤æ¢ **NixlAgentMetadata**ï¼ˆå¯¹ç«¯ QP/åŸºå€/å¸ƒå±€ï¼‰ï¼Œå†ç”¨ **nixlï¼ˆRDMAï¼‰** ç›´æ¥æŠŠè¿œç«¯å— **DMA åˆ°æœ¬åœ° KV**ã€‚
4. å¦‚æœä½¿ç”¨ **CPU ç¼“å†²**ï¼ŒæŒ‰éœ€åš **GPUâ†”CPU** çš„å—æ‹·è´ä¸ä¿å­˜ã€‚
5. **`remote_block_ids` ä¸ºç©º**ï¼ˆæ¯”å¦‚ prompt < blockï¼‰æ—¶ï¼Œ**æ•´ä¸ª RDMA æ‹‰å–è·¯å¾„ä¸ä¼šè¢«è§¦å‘**ã€‚

å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘å¯ä»¥ç»§ç»­æŠŠ **`get_num_new_matched_tokens / update_state_after_alloc / build_connector_meta / request_finished`** çš„å®Œæ•´è°ƒç”¨é“¾é…ä¸Šâ€œè¾“å…¥è¾“å‡ºæ ·ä¾‹â€å’Œâ€œå…¸å‹æ—¶åºï¼ˆprefillâ†’decodeâ†’finishï¼‰â€ï¼Œè¿™æ ·ä½ è°ƒè¯•æ—¶èƒ½ç›´æ¥å¯¹ç…§æ—¥å¿—ä¸çŠ¶æ€ã€‚







# æ¡æ‰‹å‡½æ•° handshake

ä½ è´´çš„è¿™æ®µä»£ç æ˜¯ **vLLM ä¸­ NIXL çš„ handshakeï¼ˆæ¡æ‰‹ï¼‰æµç¨‹**ï¼Œæˆ‘æ¥é€è¡Œè§£é‡Šä¸€ä¸‹å‘ç”Ÿäº†ä»€ä¹ˆï¼Œä»¥åŠè®¾è®¡æ„å›¾ï¼š

------

### å‡½æ•°å®šä¹‰

```python
def _background_nixl_handshake(self, req_id: str,
                               remote_engine_id: EngineId, meta: ReqMeta):
```

- è¿™æ˜¯ä¸€ä¸ªç§æœ‰æ–¹æ³•ï¼Œç”¨æ¥å’Œ **è¿œç«¯ engineï¼ˆworkerï¼‰** å»ºç«‹ NIXL çš„è¿æ¥ã€‚
- `req_id`: å½“å‰è¯·æ±‚çš„ ID
- `remote_engine_id`: è¦è¿æ¥çš„è¿œç«¯ engine æ ‡è¯†
- `meta`: è¯·æ±‚å…ƒæ•°æ®ï¼Œé‡Œé¢æœ‰è¿œç«¯çš„ hostã€portã€tp_size ç­‰ä¿¡æ¯

------

### 1. æ£€æŸ¥æ˜¯å¦å·²æœ‰ handshake future

```python
fut = self._handshake_futures.get(remote_engine_id)
if fut is None:
    fut = self._handshake_initiation_executor.submit(
        self._nixl_handshake, meta.remote_host, meta.remote_port,
        meta.tp_size, remote_engine_id)
    self._handshake_futures[remote_engine_id] = fut
```

- `_handshake_futures` æ˜¯ä¸ª dictï¼Œç”¨æ¥è®°å½•æŸä¸ª `remote_engine_id` çš„ handshake æ˜¯å¦å·²ç»åœ¨è¿›è¡Œã€‚
- å¦‚æœæ²¡æœ‰ï¼ˆ`None`ï¼‰ï¼Œå°±é€šè¿‡çº¿ç¨‹æ± ï¼ˆ`_handshake_initiation_executor`ï¼‰**å¼‚æ­¥æäº¤**ä¸€ä¸ª `_nixl_handshake` ä»»åŠ¡ã€‚
- è¿™æ · handshake å°±ä¸ä¼šé˜»å¡ä¸»çº¿ç¨‹ã€‚

------

### 2. ç»™ handshake future æ³¨å†Œå›è°ƒï¼ˆdone_callbackï¼‰

```python
def done_callback(f: Future[dict[int, str]], eid=remote_engine_id):
    with self._handshake_lock:
        del self._handshake_futures[eid]
        try:
            self._remote_agents[eid] = f.result()
        except Exception:
            logger.exception("Handshake with %s failed", eid)

fut.add_done_callback(done_callback)
```

- å½“ `fut`ï¼ˆhandshakeï¼‰å®Œæˆæ—¶ï¼Œä¼šè°ƒç”¨ `done_callback`ã€‚
- åœ¨å›è°ƒé‡Œï¼š
  1. ä» `_handshake_futures` é‡Œåˆ é™¤è¿™ä¸ª futureï¼ˆå› ä¸ºå·²ç»å®Œæˆäº†ï¼‰ã€‚
  2. å¦‚æœæˆåŠŸï¼Œ`f.result()` ä¼šè¿”å›è¿œç«¯ agent çš„ä¿¡æ¯ï¼ˆä¸€ä¸ª dictï¼‰ï¼Œå­˜åˆ° `_remote_agents[eid]` é‡Œã€‚
  3. å¦‚æœå¤±è´¥ï¼Œè®°å½•æ—¥å¿—ã€‚

è¿™ä¿è¯äº†ï¼š

- handshake æˆåŠŸ â†’ åç»­é€šä¿¡å¯ä»¥ç”¨ `_remote_agents`ã€‚
- handshake å¤±è´¥ â†’ ä¸ä¼šè®© future æ®‹ç•™åœ¨ `_handshake_futures` é‡Œã€‚

------

### 3. å†ç»™ handshake æ³¨å†Œå¦ä¸€ä¸ªå›è°ƒï¼ˆrequest_readyï¼‰

```python
def request_ready(_f: Future[Any], entry=(req_id, meta)):
    self._ready_requests.put(entry)

fut.add_done_callback(request_ready)
```

- ä¸ç®¡ handshake æˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œè¿™ä¸ªå›è°ƒéƒ½ä¼šæ‰§è¡Œã€‚
- å®ƒæŠŠ `(req_id, meta)` æ”¾å…¥ `_ready_requests` é˜Ÿåˆ—é‡Œï¼Œè¡¨ç¤º **è¯·æ±‚å·²ç»å‡†å¤‡å¥½ï¼Œå¯ä»¥è¢«è°ƒåº¦å¤„ç†**ã€‚

è¿™é‡Œæœ‰ç‚¹å€¼å¾—æ³¨æ„çš„ç‚¹ï¼š

- æ³¨é‡Šé‡Œå†™äº†ï¼š

  ```python
  # TODO: handle failure state of future in the
  # callback, we want to fail the request in this case.
  ```

  æ„æ€æ˜¯ç°åœ¨é€»è¾‘æœ‰ç‚¹ç²—ç³™ â€”â€” handshake å°±ç®—å¤±è´¥äº†ï¼Œä¹Ÿä¼šæŠŠè¯·æ±‚æ”¾è¿› `_ready_requests`ï¼Œè¿™ä¼šå¯¼è‡´åç»­å¤„ç†é‡åˆ°é—®é¢˜ã€‚

- å°†æ¥åº”è¯¥æ”¹è¿›ä¸ºï¼šåªæœ‰ handshake æˆåŠŸï¼Œæ‰è¿›å…¥ `_ready_requests`ï¼›å¤±è´¥çš„è¯è¦æ˜¾å¼ fail æ‰è¯·æ±‚ã€‚

------

### ğŸ§© æ€»ç»“ä¸€ä¸‹æµç¨‹

1. æ¯ä¸ªè¿œç«¯ engine åªä¼šæœ‰ä¸€ä¸ª handshake futureã€‚
2. handshake åœ¨åå°çº¿ç¨‹æ± å¼‚æ­¥æ‰§è¡Œã€‚
3. æˆåŠŸæ—¶ â†’ è®°å½• `_remote_agents`ã€‚
4. å¤±è´¥æ—¶ â†’ æ‰“æ—¥å¿—ï¼ˆTODO: åº”è¯¥ fail è¯·æ±‚ï¼‰ã€‚
5. ä¸ç®¡æˆåŠŸå¤±è´¥ï¼Œéƒ½ä¼šæŠŠè¯·æ±‚æ”¾åˆ° `_ready_requests`ï¼Œä¾›åç»­è°ƒåº¦ã€‚

------

ğŸ‘‰ ç”¨ä¸€å¥è¯æ¦‚æ‹¬ï¼š
 **è¿™ä¸ªå‡½æ•°å°±æ˜¯è´Ÿè´£â€œå‘èµ·ä¸€æ¬¡ NIXL è¿œç«¯è¿æ¥çš„æ¡æ‰‹è¿‡ç¨‹ï¼Œå¹¶åœ¨æ¡æ‰‹å®Œæˆåï¼ŒæŠŠå¯¹åº”è¯·æ±‚æ”¾åˆ°å°±ç»ªé˜Ÿåˆ—é‡Œç­‰å¾…å¤„ç†â€ã€‚**

è¦ä¸è¦æˆ‘å¸®ä½ ç”»ä¸€å¼  **æ—¶åºå›¾**ï¼ŒæŠŠ â€œè¯·æ±‚å‘èµ· â†’ handshake â†’ future å›è°ƒ â†’ è¯·æ±‚è¿›å…¥ ready é˜Ÿåˆ—â€ è¿™ä¸ªæµç¨‹ç›´è§‚ç”»å‡ºæ¥ï¼Ÿ





# æ³¨å†Œkvcacheè§£æ

è¿™æ®µä»£ç æ˜¯ **vLLM/NIXL é‡Œè®¾ç½® KV cache çš„ä¼ è¾“ region**ï¼Œæ³¨é‡Šé‡Œå·²ç»ç‚¹æ˜ï¼šå®ƒæ˜¯å¯¹åŸå§‹ region setup çš„ä¿®æ”¹ï¼Œç”¨äºæ”¯æŒä¸åŒçš„ memory layoutã€‚ä¸‹é¢æˆ‘é€æ¡è§£é‡Šä¸€ä¸‹ï¼š

------

### ğŸ”‘ èƒŒæ™¯

åœ¨åˆ†å¸ƒå¼æ¨ç†/è®­ç»ƒé‡Œï¼Œ**KV cacheï¼ˆKey/Value ç¼“å­˜ï¼‰**éœ€è¦åœ¨ä¸åŒ GPU/èŠ‚ç‚¹ä¹‹é—´é«˜æ•ˆä¼ è¾“ã€‚å¦‚ä½•ç»„ç»‡ Kã€V çš„å†…å­˜å¸ƒå±€ï¼Œä¼šç›´æ¥å½±å“ï¼š

- å…ƒæ•°æ®å¤§å°ï¼ˆNixlAgentMetadata ç¼–ç è´Ÿæ‹…ï¼‰
- é€šä¿¡æ—¶èƒ½å¦é«˜æ•ˆåˆ©ç”¨ RDMA/NCCL
- ç®—æ³•ï¼ˆFlashAttentionã€MLA ç­‰ï¼‰çš„é€‚é…æ€§

------

### ğŸ“œ æ³¨é‡Šé‡Œçš„å¯¹æ¯”

```python
# K and V are now in different regions.
#   Advantage: æ”¯æŒ MLAï¼ˆmulti-head layout attentionï¼‰å’Œéè¿ç»­å†…å­˜çš„ K/V tensor
#   Disadvantage: å…ƒæ•°æ®å˜å¤§ï¼ˆ8KB vs 5KBï¼‰

# FlashInfer: K å’Œ V åˆå¹¶åœ¨åŒä¸€ä¸ª tensor
#   Advantage: æ›´å¥½åœ°åˆ©ç”¨å†…å­˜å¸ƒå±€ï¼ˆnum_blocks åœ¨ç¬¬ä¸€ä¸ªç»´åº¦ï¼‰ï¼Œå‡å°‘å…ƒæ•°æ®å¤§å°
```

- **MLA & éè¿ç»­ KV** â†’ éœ€è¦ K å’Œ V å•ç‹¬å­˜å‚¨ï¼ˆregion æ‹†å¼€ï¼‰ï¼Œå¦åˆ™éš¾ä»¥æ­£ç¡®ç´¢å¼•ã€‚
- **FlashInfer** â†’ æŠŠ Kã€V æ”¾åˆ°åŒä¸€ä¸ªè¿ç»­çš„ tensorï¼Œèƒ½å……åˆ†åˆ©ç”¨æ‰¹é‡ DMA/è¿ç»­è®¿å­˜ï¼ŒèŠ‚çœ metadataã€‚

æ‰€ä»¥è¿™æ˜¯ä¸ª **åœ¨çµæ´»æ€§å’Œæ•ˆç‡ä¹‹é—´çš„å–èˆ**ã€‚

------

### ğŸ“¦ æ ¸å¿ƒå¾ªç¯

```python
for cache_or_caches in xfer_buffers.values():
    # Normalize to always be a list of caches
    cache_list = [cache_or_caches] if use_mla \
                 or self._use_pallas_v1 or self._use_flashinfer \
                 else cache_or_caches
```

- `xfer_buffers`ï¼šä¸åŒå±‚ï¼ˆlayerï¼‰çš„ KV ç¼“å†²åŒºã€‚
- å› ä¸ºæœ‰çš„å®ç°ï¼ˆæ¯”å¦‚ MLA/FlashInferï¼‰æ¯å±‚åªä¼šæœ‰ä¸€ä¸ª tensorï¼Œæœ‰çš„å®ç°å¯èƒ½æ˜¯å¤šä¸ª tensorï¼Œæ‰€ä»¥è¿™é‡Œå…ˆ**æ ‡å‡†åŒ–æˆ list**ã€‚

------

### ğŸ§® åœ°å€å’Œ region ä¿¡æ¯

```python
for cache in cache_list:
    base_addr = cache.data_ptr()
    region_len = self.num_blocks * self.block_len
    # NOTE: use tp_rank for device_id since multi-node TP is rarely used.
    caches_data.append((base_addr, region_len, self.tp_rank, ""))
    kv_caches_base_addr.append(base_addr)
```

- `base_addr = cache.data_ptr()`
   å–å‡ºè¯¥ KV ç¼“å†²åŒºåœ¨ device å†…å­˜ä¸­çš„ **èµ·å§‹åœ°å€**ã€‚
- `region_len = self.num_blocks * self.block_len`
   æ¯ä¸ª region çš„é•¿åº¦ï¼ˆä»¥ block ä¸ºå•ä½ï¼‰ã€‚
- `caches_data.append((base_addr, region_len, self.tp_rank, ""))`
   ä¿å­˜ region å…ƒä¿¡æ¯ï¼ˆåœ°å€ + é•¿åº¦ + æ‰€å± device id/tp_rankï¼‰ã€‚
   è¿™é‡Œç”¨ `tp_rank` ä½œä¸º `device_id`ï¼Œå› ä¸ºå¤šèŠ‚ç‚¹å¼ é‡å¹¶è¡Œï¼ˆTPï¼‰å‡ ä¹ä¸ç”¨ã€‚
- `kv_caches_base_addr.append(base_addr)`
   å•ç‹¬è®°å½•æ¯ä¸ª KV cache çš„åŸºå€ï¼Œæ–¹ä¾¿åç»­æŒ‰å±‚ç´¢å¼•ã€‚

------

### ğŸ“Š ç»Ÿè®¡ä¿¡æ¯

```python
self.kv_caches_base_addr[self.engine_id] = kv_caches_base_addr
self.num_regions = len(caches_data)
self.num_layers = len(xfer_buffers.keys())
```

- æŠŠè¿™ä¸€å¼•æ“ï¼ˆengine_idï¼‰çš„ KV cache åœ°å€ä¿å­˜èµ·æ¥ã€‚
- `num_regions`ï¼šæ€»å…±å¤šå°‘å— regionï¼ˆå’Œ KV åˆ’åˆ†æ–¹å¼æœ‰å…³ï¼ŒMLA ä¼šæ¯” FlashInfer å¤šï¼‰ã€‚
- `num_layers`ï¼šå¤šå°‘å±‚ Transformer å±‚éœ€è¦ä¼ è¾“ã€‚

------

### ğŸ“ æ€»ç»“

è¿™æ®µä»£ç çš„ä½œç”¨æ˜¯ï¼š
 **æŠŠæ¯ä¸€å±‚çš„ KV cache è½¬æ¢æˆä¸€ç³»åˆ—å†…å­˜ regionï¼ˆèµ·å§‹åœ°å€ + é•¿åº¦ + è®¾å¤‡ä¿¡æ¯ï¼‰ï¼Œå¹¶ä¿å­˜ä¸‹æ¥ï¼Œä¾›åç»­ NIXL/FlashInfer é€šä¿¡å±‚è¿›è¡Œæ•°æ®ä¼ è¾“ã€‚**

- **MLA / éè¿ç»­ KV** â†’ Kã€V æ‹†æˆä¸åŒ regionï¼Œmetadata å¤§ï¼Œä½†çµæ´»ã€‚
- **FlashInfer** â†’ Kã€V æ”¾åœ¨åŒä¸€ä¸ª tensorï¼Œmetadata å°ï¼Œæ›´é«˜æ•ˆã€‚

------

è¦ä¸è¦æˆ‘å¸®ä½ ç”»ä¸€å¼ å¯¹æ¯”å›¾ï¼ˆMLA vs FlashInfer çš„ KV å†…å­˜å¸ƒå±€ï¼‰ï¼Œç›´è§‚å±•ç¤º **K/V åˆ†å¼€ vs åˆå¹¶** çš„åŒºåˆ«ï¼Ÿ







# æ·»åŠ è¿œç«¯ä»£ç†

è¿™æ®µå‡½æ•°æ³¨é‡Šè§£é‡Šçš„æ˜¯ **NIXL é‡Œå¦‚ä½•æŠŠè¿œç«¯ agentï¼ˆæŒæœ‰ KV cache çš„ TP workerï¼‰æ³¨å†Œè¿›æ¥ï¼Œå¹¶å»ºç«‹æœ¬åœ°è¯»å–æ˜ å°„å…³ç³»**ã€‚
 æˆ‘å¸®ä½ æ‹†å¼€è®²ä¸€ä¸‹æ ¸å¿ƒå«ä¹‰ï¼ˆå°¤å…¶æ˜¯ homogeneous vs heterogeneous TP çš„å·®åˆ«ï¼‰ï¼š

------

## ğŸ”‘ èƒŒæ™¯

- **D** = Decoder é˜¶æ®µçš„ TP workerï¼ˆæ¨¡å‹è§£ç æ—¶çš„å¹¶è¡Œ workerï¼‰
- **P** = Prefix é˜¶æ®µçš„ TP workerï¼ˆKV cache æ¥æºçš„ workerï¼Œå¯èƒ½æ˜¯ prefix/prompt é˜¶æ®µè®¡ç®—å‡ºæ¥çš„ KVï¼‰

ä¸¤è¾¹çš„ TP å¤§å°ï¼ˆ`D.world_size` å’Œ `P.world_size`ï¼‰å¯èƒ½ä¸€è‡´ï¼ˆåŒæ„ï¼‰ä¹Ÿå¯èƒ½ä¸åŒï¼ˆå¼‚æ„ï¼‰ã€‚
 å‡½æ•° `add_remote_agent` å°±æ˜¯ä¸º **D worker å¦‚ä½•ä» P worker æ‹‰å– KV cache** è®¾å®šè§„åˆ™ã€‚

------

## ğŸ“œ åŒæ„ TPï¼ˆhomogeneousï¼‰

- **æ¡ä»¶**ï¼š`D.world_size == P.world_size`
- **æ˜ å°„å…³ç³»**ï¼šä¸€ä¸€å¯¹åº”
  - æœ¬åœ° rank_i â†” è¿œç«¯ rank_i
  - æ¯ä¸ª D worker ç›´æ¥æ‹‰å–è‡ªå·±å¯¹åº” rank çš„å…¨éƒ¨ KV cache

è¿™ç§æƒ…å†µæœ€ç®€å•ï¼Œ`tp_ratio = 1`ã€‚

------

## ğŸ“œ å¼‚æ„ TPï¼ˆheterogeneousï¼‰

- **æ¡ä»¶**ï¼š`D.world_size > P.world_size`
- **tp_ratio = D.world_size // P.world_size`**ï¼ˆæ•´é™¤å‡è®¾æˆç«‹ï¼‰

æ„å‘³ç€ï¼š**å¤šä¸ª Decoder worker éœ€è¦å…±äº«ä¸€ä¸ª Prefix worker çš„ KV cache**ã€‚

### æ³¨é‡Šä¸­çš„ä¾‹å­

- **D.world_size = 4**ï¼ˆDecoder æœ‰ 4 ä¸ª workerï¼‰
- **P.world_size = 2**ï¼ˆPrefix æœ‰ 2 ä¸ª workerï¼‰
- **tp_ratio = 4 // 2 = 2**

æ˜ å°„å…³ç³»ï¼ˆæŒ‰ç…§ kv_heads ç»´åº¦æ‹†åˆ†ï¼‰ï¼š

| rank_offset | p_remote_tp_rank | Decoder Worker | KV cache slice |
| ----------- | ---------------- | -------------- | -------------- |
| 0           | 0                | D-Worker0      | KV çš„å‰ä¸€åŠå¤´  |
| 1           | 0                | D-Worker1      | KV çš„åä¸€åŠå¤´  |
| 0           | 1                | D-Worker2      | KV çš„å‰ä¸€åŠå¤´  |
| 1           | 1                | D-Worker3      | KV çš„åä¸€åŠå¤´  |

è§£é‡Šï¼š

- Prefix Worker0 çš„ KV cache è¢« **D-Worker0ã€D-Worker1** æŒ‰ kv_heads æ‹†åˆ†æˆä¸¤åŠå…±äº«ã€‚
- Prefix Worker1 çš„ KV cache è¢« **D-Worker2ã€D-Worker3** æ‹†åˆ†å…±äº«ã€‚

------

## ğŸ“ Tensor Layout å·®åˆ«

- **Prefix Worker çš„ KV cache**:
   `[2, num_blocksP, kv_heads, block_size, head_dim]`
   ï¼ˆå…¶ä¸­ 2 æ˜¯ K/V ä¸¤ä¸ªç¼“å­˜ï¼‰
- **Decoder Worker çš„ KV cache**:
   `[2, num_blocksD, kv_heads // tp_ratio, block_size, head_dim]`

å³ **Decoder Worker åªæ‹¿åˆ° kv_heads çš„ä¸€éƒ¨åˆ†**ï¼ˆå¤´æ•°è¢«åˆ†å‰²ï¼‰ã€‚

è¦æ±‚ `num_blocksD >= num_blocksP`ï¼Œè¿™æ · Decoder æœ‰è¶³å¤Ÿ block å®¹çº³ Prefix cacheã€‚

------

## ğŸ“œ MLA çš„ç‰¹ä¾‹

- MLA ä¸‹ï¼Œcache æ˜¯ **å®Œå…¨å¤åˆ¶**ç»™æ‰€æœ‰ TP worker çš„ã€‚
- æ‰€ä»¥ **rank_offset å›ºå®šä¸º 0**ï¼Œæ¯ä¸ª Decoder Worker éƒ½ç›´æ¥å…±äº«å®Œæ•´çš„ cacheï¼Œä¸åš kv_heads åˆ‡åˆ†ã€‚

------

## âœ… æ€»ç»“

`add_remote_agent` çš„é€»è¾‘æ ¸å¿ƒæ˜¯ï¼š

1. **æ³¨å†Œè¿œç«¯ KV cache** çš„åŸºæœ¬ä¿¡æ¯ï¼ˆåœ°å€ã€æè¿°ç¬¦ï¼‰ã€‚
2. æ ¹æ® **TP æ‹“æ‰‘ï¼ˆåŒæ„ or å¼‚æ„ï¼‰** å†³å®š D worker å¦‚ä½•æ˜ å°„åˆ° P workerï¼š
   - åŒæ„ â†’ rank å¯¹ rankï¼Œä¸€ä¸€å¯¹åº”ã€‚
   - å¼‚æ„ â†’ å¤šä¸ª D worker åˆ†æ‘ŠåŒä¸€ä¸ª P worker çš„ KV cacheï¼ˆæŒ‰ kv_heads ç»´åº¦åˆ‡åˆ†ï¼‰ã€‚
3. MLA æƒ…å†µä¸‹ï¼Œcache ç›´æ¥å¹¿æ’­ï¼Œrank_offset æ€»æ˜¯ 0ã€‚

------

è¦ä¸è¦æˆ‘å¸®ä½ ç”»ä¸€å¼  **ç¤ºæ„å›¾**ï¼ˆ2 ä¸ª Prefix worker â†’ 4 ä¸ª Decoder workerï¼ŒKV cache å¦‚ä½•è¢«åˆ‡åˆ†/å…±äº«ï¼‰ï¼Œç›´è§‚å±•ç¤ºè¿™æ®µæ³¨é‡Šé‡Œçš„ rank_offset æ˜ å°„å…³ç³»ï¼Ÿ







# å‡†å¤‡ä»¥åŠå‘åŒ…æµç¨‹/è¯»blockè¯·æ±‚ä¸ºä¾‹

```c
        # Prepare transfer with Nixl.
        handle = self.nixl_wrapper.make_prepped_xfer(
            "READ",
            local_xfer_side_handle,
            local_block_descs_ids,
            remote_xfer_side_handle,
            remote_block_descs_ids,
            notif_msg=notif_id,
        )

        # Begin async xfer.
        self.nixl_wrapper.transfer(handle)
```

ä½ è´´çš„è¿™æ®µä»£ç åŸºæœ¬ä¸Šæ˜¯ **NIXL å±‚å‘èµ·ä¸€æ¬¡è¿œç«¯æ•°æ®ä¼ è¾“** çš„å…¸å‹æµç¨‹ï¼Œæˆ‘å¸®ä½ æ‹†å¼€è§£é‡Šä¸€ä¸‹ï¼š

```python
# 1. å‡†å¤‡ä¼ è¾“ (prepare)
handle = self.nixl_wrapper.make_prepped_xfer(
    "READ",                          # ä¼ è¾“ç±»å‹ï¼šREAD/WRITE
    local_xfer_side_handle,          # æœ¬åœ°ä¸€ä¾§çš„ä¼ è¾“ç«¯ handle
    local_block_descs_ids,           # æœ¬åœ° block æè¿°ç¬¦ ID åˆ—è¡¨
    remote_xfer_side_handle,         # è¿œç«¯ä¸€ä¾§çš„ä¼ è¾“ç«¯ handle
    remote_block_descs_ids,          # è¿œç«¯ block æè¿°ç¬¦ ID åˆ—è¡¨
    notif_msg=notif_id,              # å¯é€‰çš„é€šçŸ¥ IDï¼Œç”¨äºå®Œæˆæ—¶çš„å›è°ƒæˆ–äº‹ä»¶æ ‡è¯†
)
```

- `make_prepped_xfer()` çš„ä½œç”¨æ˜¯æ ¹æ® **ä¼ è¾“æ–¹å‘ + åŒæ–¹çš„ block æè¿°ç¬¦** åˆ›å»ºä¸€ä¸ªä¼ è¾“ä¸Šä¸‹æ–‡ï¼ˆhandleï¼‰ã€‚
  - åœ¨ **READ** æ¨¡å¼ä¸‹ï¼Œè¡¨ç¤ºâ€œä»è¿œç«¯è¯»åˆ°æœ¬åœ°â€ï¼Œæ‰€ä»¥æœ¬åœ°çš„å†…å­˜æ˜¯ç›®æ ‡ï¼Œè¿œç«¯çš„å†…å­˜æ˜¯æºã€‚
  - `local_block_descs_ids` å’Œ `remote_block_descs_ids` å¯¹åº”çš„æ˜¯ **é¢„å…ˆæ³¨å†Œè¿‡çš„ KV cache block æˆ–è€… tensor åˆ†ç‰‡**ã€‚
  - è¿™ä¸€æ­¥ä¸ä¼šçœŸæ­£å‘èµ·æ•°æ®ä¼ è¾“ï¼Œåªæ˜¯ç”Ÿæˆä¸€ä¸ªå¯æäº¤çš„ä¼ è¾“è¯·æ±‚å¥æŸ„ï¼ˆhandleï¼‰ã€‚

```python
# 2. å¼‚æ­¥æäº¤ä¼ è¾“ (kick off transfer)
self.nixl_wrapper.transfer(handle)
```

- `transfer(handle)` å°±æ˜¯çœŸæ­£æŠŠå‡†å¤‡å¥½çš„ä¼ è¾“è¯·æ±‚æäº¤ç»™ NIXL åç«¯æ‰§è¡Œï¼ˆæ¯”å¦‚ RDMA åŠ¨ä½œï¼‰ã€‚
- è¿™æ˜¯ **å¼‚æ­¥** çš„ï¼šè°ƒç”¨ä¼šç«‹å³è¿”å›ï¼Œæ•°æ®åœ¨åå° DMA ä¼ è¾“ï¼Œç­‰å®Œæˆåå†é€šè¿‡ `notif_id` æˆ– future/promise çš„æœºåˆ¶é€šçŸ¥ä¸Šå±‚ã€‚

------

### å°ç»“

è¿™ä¸¤è¡Œçš„é€»è¾‘å°±æ˜¯ï¼š

1. **make_prepped_xfer()** â€”â€” æ ¹æ® local/remote æè¿°ç¬¦ï¼Œç”Ÿæˆä¸€ä¸ªå¾…æ‰§è¡Œçš„ä¼ è¾“ä»»åŠ¡ï¼ˆhandleï¼‰ã€‚
2. **transfer(handle)** â€”â€” æŠŠè¿™ä¸ªä¼ è¾“ä»»åŠ¡æäº¤ç»™ NIXLï¼Œå¯åŠ¨çœŸæ­£çš„å¼‚æ­¥æ•°æ®ä¼ è¾“ã€‚

è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼š

- **åˆ†ç¦»å‡†å¤‡å’Œæ‰§è¡Œ** â†’ å¯ä»¥å…ˆæ‰¹é‡ç”Ÿæˆ handleï¼Œå†ä¸€èµ·æäº¤ï¼Œå‡å°‘æ§åˆ¶é¢ overheadã€‚
- **å¼‚æ­¥æ‰§è¡Œ** â†’ ä¸ä¼šé˜»å¡è®¡ç®—çº¿ç¨‹ï¼Œå¯ä»¥å’Œè®¡ç®—æµæ°´å¹¶è¡Œã€‚

------

è¦ä¸è¦æˆ‘å¸®ä½ ç”»ä¸€ä¸ª **READ æ•°æ®æµå‘ç¤ºæ„å›¾**ï¼ˆæœ¬åœ°ç¼“å­˜ block â¬…ï¸ RDMA â¬…ï¸ è¿œç«¯ç¼“å­˜ blockï¼‰ï¼Ÿè¿™æ ·æ›´ç›´è§‚ç†è§£ã€‚





# æ„é€ è¯·æ±‚è°ƒç”¨æ ˆ

```bash
handle = self.nixl_wrapper.make_prepped_xfer
nixlAgent::makeXferReq 
handle->initiatorDescs = new nixl_meta_dlist_t 
handle->targetDescs    = new nixl_meta_dlist_t
ret = handle->engine->prepXfer
handle = new nixlUcxBackendH
```





# nixlæ¥å£å®ç°

![image-20250820144600170](/Users/xb/Library/Application Support/typora-user-images/image-20250820144600170.png)



# nixlä¼ è¾“

```bash
status = self.agent.postXferReq(handle, notif_msg) -> nixlAgent::postXferReq
req_hndl->status = req_hndl->engine->postXfer
nixlUcxEngine::postXfer // ucxåç«¯å®ç°
sendXferRange
auto &ep = rmd->conn->getEp(workerId)
ret = ep->read or ret = ep->write
ä»¥readä¸ºä¾‹:
ucs_status_ptr_t request = ucp_get_nbx

writeä¸ºä¾‹:
ucs_status_ptr_t request = ucp_put_nbx
```





# nixlå¤šç§åç«¯å‘é€å®ç°

![image-20250820145730616](/Users/xb/Library/Application Support/typora-user-images/image-20250820145730616.png)









